{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73efbe97",
   "metadata": {},
   "source": [
    "## Importing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739fa5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     name         roles  specialities        lane possible_lanes  \\\n",
      "0   1     Miya      Marksman   Reap,Damage  Gold Laner            NaN   \n",
      "1   2  Balmond       Fighter  Damage,Regen     Jungler      Exp Laner   \n",
      "2   3    Saber      Assassin   Charge,Reap      Roamer        Jungler   \n",
      "3   4    Alice     Mage,Tank  Charge,Regen   Exp Laner        Jungler   \n",
      "4   5     Nana  Mage,Support    Poke,Burst   Mid Laner            NaN   \n",
      "\n",
      "                                                icon  \n",
      "0  https://static.wikia.nocookie.net/mobile-legen...  \n",
      "1  https://static.wikia.nocookie.net/mobile-legen...  \n",
      "2  https://static.wikia.nocookie.net/mobile-legen...  \n",
      "3  https://static.wikia.nocookie.net/mobile-legen...  \n",
      "4  https://static.wikia.nocookie.net/mobile-legen...  \n",
      "131\n",
      "Index(['id', 'name', 'roles', 'specialities', 'lane', 'possible_lanes',\n",
      "       'icon'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "df = pd.read_csv('data/heroes_updated.csv')\n",
    "df_match_history = pd.read_csv('data/toBe7_process_FulldraftWinLose.csv') # needs to be replaced by full match history dataset\n",
    "print(df.head())        \n",
    "print(len(df))          \n",
    "print(df.columns)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6291cef",
   "metadata": {},
   "source": [
    "## Preprocessing of data\n",
    "1. df_hero_id to show id and name only for encoding_state\n",
    "2. df_role to show name and role \n",
    "3. df_specialty to show name and specialty\n",
    "4. df_lane to show name and lane/possible lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4b14497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Saber\n",
      "Assassin\n",
      "Charge,Reap\n",
      "Roamer\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "df_hero_to_id = {row['name']: row['id'] - 1 for _, row in df.iterrows()}\n",
    "df_id_to_hero = {v: k for k, v in df_hero_to_id.items()}\n",
    "df_role = {row['name']: row['roles'] for _, row in df.iterrows()}\n",
    "df_specialities = {row['name']: row['specialities'] for _, row in df.iterrows()}\n",
    "df_lane = {row['name']: row['lane'] for _, row in df.iterrows()}\n",
    "\n",
    "# Example usage:\n",
    "print(df_hero_to_id[\"Saber\"])\n",
    "print(df_id_to_hero[2])\n",
    "print(df_role[\"Saber\"])\n",
    "print(df_specialities[\"Saber\"])\n",
    "print(df_lane[\"Saber\"])\n",
    "\n",
    "# Total Dimension / Available Heroes\n",
    "print(len(df_hero_to_id))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a9a828",
   "metadata": {},
   "source": [
    "## Banned Hero Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6416fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ['Miya', 'Balmond', 'Saber', 'Alice', 'Nana', 'Tigreal', 'Alucard', 'Karina', 'Akai', 'Franco', 'Bane', 'Bruno', 'Clint', 'Rafaela', 'Eudora', 'Zilong', 'Fanny', 'Layla', 'Minotaur', 'Lolita', 'Hayabusa', 'Freya', 'Gord', 'Natalia', 'Kagura', 'Chou', 'Sun', 'Alpha', 'Ruby', 'Yi Sun-shin', 'Moskov', 'Johnson', 'Cyclops', 'Estes', 'Hilda', 'Aurora', 'Lapu-Lapu', 'Vexana', 'Roger', 'Karrie', 'Gatotkaca', 'Harley', 'Irithel', 'Grock', 'Argus', 'Odette', 'Lancelot', 'Diggie', 'Hylos', 'Zhask', 'Helcurt', 'Pharsa', 'Lesley', 'Jawhead', 'Angela', 'Gusion', 'Valir', 'Martis', 'Uranus', 'Hanabi', \"Chang'e\", 'Kaja', 'Selena', 'Aldous', 'Claude', 'Vale', 'Leomord', 'Lunox', 'Hanzo', 'Belerick', 'Kimmy', 'Thamuz', 'Harith', 'Minsitthar', 'Kadita', 'Faramis', 'Badang', 'Khufra', 'Granger', 'Guinevere', 'Esmeralda', 'Terizla', 'X.Borg', 'Ling', 'Dyrroth', 'Lylia', 'Baxia', 'Masha', 'Wanwan', 'Silvanna', 'Carmilla', 'Cecilion', 'Atlas', 'Popol and Kupa', 'Yu Zhong', 'Luo Yi', 'Benedetta', 'Khaleed', 'Barats', 'Brody', 'Yve', 'Mathilda', 'Paquito', 'Gloo', 'Beatrix', 'Phoveus', 'Natan', 'Aulus', 'Aamon', 'Floryn', 'Valentina', 'Edith', 'Yin', 'Melissa', 'Xavier', 'Julian', 'Fredrinn', 'Joy', 'Novaria', 'Arlott', 'Ixia', 'Nolan', 'Cici', 'Chip', 'Zhuxin', 'Suyou', 'Lukas', 'Kalea', 'Zetian', 'Obsidia', 'Sora'] heroes.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Scraped from mobilelegends.com/rank\n",
    "# 2/17/2026\n",
    "BAN_RATES = {\n",
    "    \"Gloo\": 81.00,        \"Sora\": 67.09,        \"Aamon\": 41.63,\n",
    "    \"Helcurt\": 37.93,     \"Freya\": 35.15,       \"Yi Sun-shin\": 33.03,\n",
    "    \"Alice\": 30.55,       \"Estes\": 28.16,       \"Diggie\": 24.59,\n",
    "    \"Saber\": 24.27,       \"Floryn\": 22.42,      \"Hayabusa\": 21.41,\n",
    "    \"Leomord\": 20.30,     \"Fredrinn\": 20.22,    \"Angela\": 18.43,\n",
    "    \"Hilda\": 18.22,       \"Lancelot\": 13.79,    \"Guinevere\": 13.37,\n",
    "    \"Ixia\": 13.28,        \"Sun\": 12.69,         \"Yu Zhong\": 11.67,\n",
    "    \"Gusion\": 11.23,      \"Franco\": 11.05,      \"Granger\": 10.72,\n",
    "    \"Grock\": 10.12,       \"Zetian\": 8.80,       \"X.Borg\": 8.02,\n",
    "    \"Hanzo\": 7.40,        \"Minotaur\": 7.40,     \"Belerick\": 7.05,\n",
    "    \"Tigreal\": 6.85,      \"Thamuz\": 6.58,       \"Minsitthar\": 6.47,\n",
    "    \"Fanny\": 6.45,        \"Kadita\": 6.15,       \"Eudora\": 6.02,\n",
    "    \"Lesley\": 5.94,       \"Lapu-Lapu\": 5.45,    \"Kalea\": 5.01,\n",
    "    \"Cici\": 4.97,         \"Rafaela\": 4.90,      \"Chip\": 4.61,\n",
    "    \"Hanabi\": 4.57,       \"Nana\": 4.34,         \"Yin\": 4.29,\n",
    "    \"Zhuxin\": 4.18,       \"Claude\": 4.16,       \"Karrie\": 4.12,\n",
    "    \"Harley\": 3.50,       \"Atlas\": 3.37,        \"Johnson\": 3.29,\n",
    "    \"Obsidia\": 3.29,      \"Julian\": 3.17,       \"Chou\": 2.85,\n",
    "    \"Miya\": 2.68,         \"Esmeralda\": 2.48,    \"Cyclops\": 2.44,\n",
    "    \"Natalia\": 2.38,      \"Lolita\": 2.25,       \"Alucard\": 2.21,\n",
    "    \"Akai\": 2.20,         \"Karina\": 2.05,       \"Joy\": 1.86,\n",
    "    \"Argus\": 1.84,        \"Lukas\": 1.80,        \"Uranus\": 1.72,\n",
    "    \"Vexana\": 1.71,       \"Silvanna\": 1.67,     \"Badang\": 1.66,\n",
    "    \"Khufra\": 1.64,       \"Carmilla\": 1.50,     \"Phoveus\": 1.47,\n",
    "    \"Arlott\": 1.45,       \"Alpha\": 1.43,        \"Pharsa\": 1.39,\n",
    "    \"Layla\": 1.36,        \"Selena\": 1.33,       \"Benedetta\": 1.29,\n",
    "    \"Suyou\": 1.17,        \"Kaja\": 1.16,         \"Clint\": 1.16,\n",
    "    \"Valir\": 1.11,        \"Hylos\": 1.07,        \"Kagura\": 1.03,\n",
    "    \"Gatotkaca\": 1.02,    \"Melissa\": 0.99,      \"Chang'e\": 0.95,\n",
    "    \"Mathilda\": 0.95,     \"Kimmy\": 0.91,        \"Lylia\": 0.90,\n",
    "    \"Ruby\": 0.80,         \"Zilong\": 0.75,       \"Faramis\": 0.73,\n",
    "    \"Wanwan\": 0.71,       \"Irithel\": 0.66,      \"Odette\": 0.65,\n",
    "    \"Martis\": 0.57,       \"Aldous\": 0.56,       \"Cecilion\": 0.54,\n",
    "    \"Dyrroth\": 0.54,      \"Valentina\": 0.53,    \"Nolan\": 0.52,\n",
    "    \"Lunox\": 0.51,        \"Khaleed\": 0.50,      \"Ling\": 0.46,\n",
    "    \"Brody\": 0.46,        \"Xavier\": 0.44,       \"Natan\": 0.42,\n",
    "    \"Jawhead\": 0.37,      \"Popol and Kupa\": 0.37, \"Paquito\": 0.35,\n",
    "    \"Terizla\": 0.35,      \"Gord\": 0.34,         \"Yve\": 0.33,\n",
    "    \"Bane\": 0.33,         \"Masha\": 0.32,        \"Zhask\": 0.32,\n",
    "    \"Balmond\": 0.32,      \"Baxia\": 0.30,        \"Aurora\": 0.30,\n",
    "    \"Vale\": 0.29,         \"Beatrix\": 0.29,      \"Moskov\": 0.27,\n",
    "    \"Aulus\": 0.23,        \"Novaria\": 0.22,      \"Roger\": 0.17,\n",
    "    \"Barats\": 0.14,       \"Luo Yi\": 0.14,       \"Edith\": 0.14,\n",
    "    \"Bruno\": 0.11,        \"Harith\": 0.11,\n",
    "}\n",
    "# Draft progression: {state: (ally_pick_count, enemy_pick_count)}\n",
    "DRAFT_STATES = {\n",
    "    'FP1': (0, 0),   # First pick, no picks yet(picking 1)\n",
    "    'FP2': (1, 2),   # First pick, ally took 1(picking 2), enemy took 2\n",
    "    'FP3': (3, 4),   # First pick, ally took 3(picking 2), enemy took 4\n",
    "    'SP1': (0, 1),   # Second pick, enemy took 1(picking 2)\n",
    "    'SP2': (2, 3),   # Second pick, ally took 2(picking 2), enemy has 3\n",
    "    'SP3': (4, 5),   # Second pick, ally took 2(picking 1), enemy has 5\n",
    "}\n",
    "\n",
    "HERO_POOL = list(df_hero_to_id)   # 131 heroes\n",
    "print(f'Loaded {HERO_POOL} heroes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f7988d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample call, getBannedHeroes():\n",
      "['Bane', 'Miya', 'Alice', 'Obsidia', 'Franco', 'Joy', 'Balmond', 'Novaria', 'Karina', 'Yu Zhong']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Pre-compute softmax weights once (temperature controls spread)\n",
    "# Higher temperature, more uniform  (less bias toward top heroes)\n",
    "# Lower  temperature, more skewed   (top heroes dominate)\n",
    "# T = 20 gives a good realistic middle ground\n",
    "TEMPERATURE = 20.0\n",
    "\n",
    "def _compute_softmax_weights(ban_rates: dict, temperature: float) -> list:\n",
    "    heroes = list(ban_rates.keys())\n",
    "    rates  = [ban_rates[h] for h in heroes]\n",
    "    scaled = [r / temperature for r in rates]\n",
    "    max_s  = max(scaled)\n",
    "    exps   = [math.exp(s - max_s) for s in scaled]\n",
    "    total  = sum(exps)\n",
    "    return [e / total for e in exps]\n",
    "\n",
    "SOFTMAX_WEIGHTS = _compute_softmax_weights(BAN_RATES, TEMPERATURE)\n",
    "\n",
    "\n",
    "def getBannedHeroes() -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of 10 unique banned heroes sampled without replacement,\n",
    "    weighted by real ban rates (softmax-scaled to avoid heavy bias).\n",
    "    \"\"\"\n",
    "\n",
    "    keys = [\n",
    "        (random.random() ** (1.0 / w), hero)\n",
    "        for hero, w in zip(HERO_POOL, SOFTMAX_WEIGHTS)\n",
    "    ]\n",
    "    keys.sort(reverse=True)\n",
    "    return [hero for weight, hero in keys[:10]]\n",
    "\n",
    "\n",
    "sample = getBannedHeroes()\n",
    "print('Sample call, getBannedHeroes():')\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e7e83",
   "metadata": {},
   "source": [
    "## Training Dataset Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b90705",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7e79ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_attr(val):\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    return [x.strip() for x in str(val).replace('/', ',').split(',')]\n",
    "\n",
    "def clean_role(r):\n",
    "    r = r.strip()\n",
    "    if r == 'Supprot': return 'Support'\n",
    "    if r == 'Jungle':  return None\n",
    "    return r\n",
    "\n",
    "def clean_lane(val):\n",
    "    lane = str(val).strip()\n",
    "    if lane == 'EXP Laner': return 'Exp Laner'\n",
    "    return lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "03715854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  winpick1   winpick2 winpick3   winpick4  winpick5 losepick1  \\\n",
      "0  Match_1    Claude       Gord   Martis    Paquito  Silvanna    Angela   \n",
      "1  Match_2     Atlas  Lapu-Lapu   Lesley     Martis    Xavier     Estes   \n",
      "2  Match_3     Atlas     Gusion   Karina    Melissa  Silvanna   Beatrix   \n",
      "3  Match_4  Fredrinn     Kadita  Terizla  Valentina    Wanwan     Brody   \n",
      "4  Match_5    Arlott     Lesley   Lolita     Pharsa  Silvanna    Aldous   \n",
      "\n",
      "  losepick2 losepick3 losepick4  losepick5  \n",
      "0     Brody     Edith      Ling     Pharsa  \n",
      "1  Fredrinn    Moskov    Pharsa   Silvanna  \n",
      "2     Fanny      Kaja    Lolita  Valentina  \n",
      "3     Freya    Julian  Lancelot   Silvanna  \n",
      "4    Franco  Fredrinn   Melissa      Valir  \n",
      "Total matches: 9122\n",
      "Unknown heroes: set()\n",
      "Total heroes: 131\n",
      "Roles: 6 | Specs: 16 | Lanes: 5\n",
      "Final vector size: 316\n",
      "\n",
      "Skipped : 0 matches\n",
      "Samples : 18244\n",
      "X shape : (18244, 316)\n",
      "y shape : (18244,)\n",
      "Wins    : 9122 | Losses: 9122\n",
      "\n",
      "Saved: data/draft_dataset_316.npz\n",
      "\n",
      "─── Sample 1 ───\n",
      "Ally  heroes : ['Pharsa', 'Angela', 'Ling', 'Brody', 'Edith']\n",
      "Enemy heroes : ['Gord', 'Martis', 'Claude', 'Silvanna', 'Paquito']\n",
      "Ally  roles  : ['Assassin', 'Mage', 'Marksman', 'Support', 'Tank']\n",
      "Enemy roles  : ['Fighter', 'Mage', 'Marksman']\n",
      "Ally  specs  : ['Burst', 'Chase', 'Control', 'Guard', 'Poke', 'Reap', 'Support']\n",
      "Enemy specs  : ['Burst', 'Charge', 'Chase', 'Damage', 'Initiator', 'Magic Damage', 'Poke', 'Reap']\n",
      "Ally  lanes  : ['Exp Laner', 'Gold Laner', 'Jungler', 'Mid Laner', 'Roamer']\n",
      "Enemy lanes  : ['Exp Laner', 'Gold Laner', 'Mid Laner']\n",
      "Label        : 0  (1=ally wins, 0=ally loses)\n",
      "\n",
      "─── Sample 2 ───\n",
      "Ally  heroes : ['Lapu-Lapu', 'Lesley', 'Martis', 'Atlas', 'Xavier']\n",
      "Enemy heroes : ['Moskov', 'Estes', 'Pharsa', 'Silvanna', 'Fredrinn']\n",
      "Ally  roles  : ['Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank']\n",
      "Enemy roles  : ['Fighter', 'Mage', 'Marksman', 'Support', 'Tank']\n",
      "Ally  specs  : ['Burst', 'Charge', 'Chase', 'Crowd Control', 'Damage', 'Guard', 'Initiator', 'Reap']\n",
      "Enemy specs  : ['Burst', 'Chase', 'Damage', 'Guard', 'Initiator', 'Magic Damage', 'Poke', 'Reap', 'Regen']\n",
      "Ally  lanes  : ['Exp Laner', 'Gold Laner', 'Mid Laner', 'Roamer']\n",
      "Enemy lanes  : ['Exp Laner', 'Gold Laner', 'Jungler', 'Mid Laner', 'Roamer']\n",
      "Label        : 1  (1=ally wins, 0=ally loses)\n"
     ]
    }
   ],
   "source": [
    "print(df_match_history.head())\n",
    "print(f\"Total matches: {len(df_match_history)}\")\n",
    "pick_cols = [f'winpick{i}' for i in range(1, 6)] + [f'losepick{i}' for i in range(1, 6)]\n",
    "for col in pick_cols:\n",
    "    df_match_history[col] = df_match_history[col].str.strip().replace(\"Change\", \"Chang'e\")\n",
    "hero_names = set(df['name'].str.strip())\n",
    "all_match_heroes = set()\n",
    "for col in pick_cols:\n",
    "    all_match_heroes.update(df_match_history[col].unique())\n",
    "missing = all_match_heroes - hero_names\n",
    "print(f\"Unknown heroes: {missing}\")  # Should be empty set()\n",
    "\n",
    "hero_to_id = {row['name'].strip(): int(row['id']) - 1 for _, row in df.iterrows()}\n",
    "id_to_hero = {v: k for k, v in hero_to_id.items()}\n",
    "NUM_HEROES = len(hero_to_id)  # 131\n",
    "print(f\"Total heroes: {NUM_HEROES}\")\n",
    "\n",
    "hero_roles = {}\n",
    "hero_specs = {}\n",
    "hero_lanes = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    name = row['name'].strip()\n",
    "    hero_roles[name] = [clean_role(r) for r in split_attr(row['roles']) if clean_role(r)]\n",
    "    hero_specs[name] = split_attr(row['specialities'])\n",
    "    hero_lanes[name] = [clean_lane(row['lane'])]\n",
    "\n",
    "# ── 6. Encoding categories ─────────────────────────────────────────────────────\n",
    "ROLES = sorted(['Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank'])\n",
    "SPECS = sorted(['Burst', 'Charge', 'Chase', 'Control', 'Crowd Control', 'Damage',\n",
    "                'Finisher', 'Guard', 'Initiator', 'Magic Damage', 'Mixed Damage',\n",
    "                'Poke', 'Push', 'Reap', 'Regen', 'Support'])\n",
    "LANES = sorted(['Exp Laner', 'Gold Laner', 'Jungler', 'Mid Laner', 'Roamer'])\n",
    "\n",
    "role_to_id = {r: i for i, r in enumerate(ROLES)}\n",
    "spec_to_id = {s: i for i, s in enumerate(SPECS)}\n",
    "lane_to_id = {l: i for i, l in enumerate(LANES)}\n",
    "\n",
    "NUM_ROLES = len(ROLES)   # 6\n",
    "NUM_SPECS = len(SPECS)   # 16\n",
    "NUM_LANES = len(LANES)   # 5\n",
    "\n",
    "print(f\"Roles: {NUM_ROLES} | Specs: {NUM_SPECS} | Lanes: {NUM_LANES}\")\n",
    "print(f\"Final vector size: {NUM_HEROES*2 + NUM_ROLES*2 + NUM_SPECS*2 + NUM_LANES*2}\")  # 316\n",
    "\n",
    "def encode_team(heroes):\n",
    "    hero_vec = np.zeros(NUM_HEROES, dtype=np.float32)\n",
    "    role_vec = np.zeros(NUM_ROLES,  dtype=np.float32)\n",
    "    spec_vec = np.zeros(NUM_SPECS,  dtype=np.float32)\n",
    "    lane_vec = np.zeros(NUM_LANES,  dtype=np.float32)\n",
    "    for h in heroes:\n",
    "        hero_vec[hero_to_id[h]] = 1.0\n",
    "        for r in hero_roles.get(h, []):\n",
    "            if r in role_to_id:\n",
    "                role_vec[role_to_id[r]] = 1.0\n",
    "        for s in hero_specs.get(h, []):\n",
    "            if s in spec_to_id:\n",
    "                spec_vec[spec_to_id[s]] = 1.0\n",
    "        for l in hero_lanes.get(h, []):\n",
    "            if l in lane_to_id:\n",
    "                lane_vec[lane_to_id[l]] = 1.0\n",
    "    return hero_vec, role_vec, spec_vec, lane_vec\n",
    "\n",
    "## Sample Usage:\n",
    "# encode_team(['Saber'])\n",
    "\n",
    "# Each match → 2 samples:\n",
    "#   Sample A: ally=win_team,  enemy=lose_team → label 1  (ally wins)\n",
    "#   Sample B: ally=lose_team, enemy=win_team  → label 0  (ally loses)\n",
    "X_win   = []\n",
    "y_win   = []\n",
    "skipped = 0\n",
    "\n",
    "for _, row in df_match_history.iterrows():\n",
    "    win_heroes  = [row[f'winpick{i}'].strip()  for i in range(1, 6)]\n",
    "    lose_heroes = [row[f'losepick{i}'].strip() for i in range(1, 6)]\n",
    "\n",
    "    if any(h not in hero_to_id for h in win_heroes + lose_heroes):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    win_h,  win_r,  win_s,  win_l  = encode_team(win_heroes)\n",
    "    lose_h, lose_r, lose_s, lose_l = encode_team(lose_heroes)\n",
    "\n",
    "    # Sample A: ally=win → label 1\n",
    "    X_win.append(np.concatenate([win_h, lose_h, win_r, lose_r, win_s, lose_s, win_l, lose_l]))\n",
    "    y_win.append(1.0)\n",
    "\n",
    "    # Sample B: ally=lose → label 0\n",
    "    X_win.append(np.concatenate([lose_h, win_h, lose_r, win_r, lose_s, win_s, lose_l, win_l]))\n",
    "    y_win.append(0.0)\n",
    "\n",
    "X_win = np.stack(X_win).astype(np.float32)  \n",
    "y_win = np.array(y_win,  dtype=np.float32)  \n",
    "\n",
    "print(f\"\\nSkipped : {skipped} matches\")\n",
    "print(f\"Samples : {len(X_win)}\")\n",
    "print(f\"X shape : {X_win.shape}\")  \n",
    "print(f\"y shape : {y_win.shape}\")   \n",
    "print(f\"Wins    : {int(y_win.sum())} | Losses: {int((1 - y_win).sum())}\")\n",
    "\n",
    "np.savez('data/draft_dataset_316.npz', X=X_win, y=y_win)\n",
    "print(\"\\nSaved: data/draft_dataset_316.npz\")\n",
    "\n",
    "def check_sample(idx):\n",
    "    s = X_win[idx]\n",
    "    ally_heroes  = [id_to_hero[i] for i in np.where(s[0:131]   == 1)[0]]\n",
    "    enemy_heroes = [id_to_hero[i] for i in np.where(s[131:262] == 1)[0]]\n",
    "    ally_roles   = [ROLES[i]      for i in np.where(s[262:268] == 1)[0]]\n",
    "    enemy_roles  = [ROLES[i]      for i in np.where(s[268:274] == 1)[0]]\n",
    "    ally_specs   = [SPECS[i]      for i in np.where(s[274:290] == 1)[0]]\n",
    "    enemy_specs  = [SPECS[i]      for i in np.where(s[290:306] == 1)[0]]\n",
    "    ally_lanes   = [LANES[i]      for i in np.where(s[306:311] == 1)[0]]\n",
    "    enemy_lanes  = [LANES[i]      for i in np.where(s[311:316] == 1)[0]]\n",
    "    print(f\"\\n─── Sample {idx} ───\")\n",
    "    print(f\"Ally  heroes : {ally_heroes}\")\n",
    "    print(f\"Enemy heroes : {enemy_heroes}\")\n",
    "    print(f\"Ally  roles  : {ally_roles}\")\n",
    "    print(f\"Enemy roles  : {enemy_roles}\")\n",
    "    print(f\"Ally  specs  : {ally_specs}\")\n",
    "    print(f\"Enemy specs  : {enemy_specs}\")\n",
    "    print(f\"Ally  lanes  : {ally_lanes}\")\n",
    "    print(f\"Enemy lanes  : {enemy_lanes}\")\n",
    "    print(f\"Label        : {int(y_win[idx])}  (1=ally wins, 0=ally loses)\")\n",
    "\n",
    "check_sample(1)   # Match 1 — ally wins\n",
    "check_sample(2)   # Match 1 — ally loses (flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "625fa67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marksman' 'Fighter' 'Assassin' 'Mage,Tank' 'Mage,Support' 'Tank,Support'\n",
      " 'Fighter,Assassin' 'Fighter,Mage' 'Support' 'Mage' 'Assassin,Fighter'\n",
      " 'Support,Tank' 'Fighter,Tank' 'Assassin,Marksman' 'Tank'\n",
      " 'Fighter,Marksman' 'Tank,Fighter' 'Mage,Assassin' 'Marksman,Assassin'\n",
      " 'Fighter,Support' 'Assassin,Mage' 'Marksman,Mage' 'Support,Mage'\n",
      " 'Support,Assassin' 'Tank,Marksman' 'Support/Tank' 'Assassin/Fighter'\n",
      " 'Supprot/Fighter' 'Fighter/Assassin']\n",
      "['Reap,Damage' 'Damage,Regen' 'Charge,Reap' 'Charge,Regen' 'Poke,Burst'\n",
      " 'Crowd Control' 'Chase,Damage' 'Reap,Magic Damage' 'Guard,Crowd Control'\n",
      " 'Initiator,Control' 'Push,Burst' 'Reap,Burst' 'Regen,Guard'\n",
      " 'Control,Burst' 'Chase,Reap' 'Chase,Burst' 'Poke,Reap' 'Chase,Control'\n",
      " 'Push,Damage' 'Charge,Damage' 'Crowd Control,Regen' 'Reap,Chase'\n",
      " 'Support,Crowd Control' 'Poke,Control' 'Crowd Control,Poke'\n",
      " 'Crowd Control,Burst' 'Burst,Poke' 'Crowd Control,Initiator'\n",
      " 'Charge,Burst' 'Guard,Poke' 'Guard,Initiator' 'Guard,Support'\n",
      " 'Burst,Magic Damage' 'Damage,Guard' 'Reap,Charge' 'Regen'\n",
      " 'Control,Charge' 'Initiator,Reap' 'Burst,Support' 'Burst,Chase'\n",
      " 'Burst,Crowd Control' 'Burst,Damage' 'Damage,Magic Damage'\n",
      " 'Initiator,Crowd Control' 'Burst,Charge' 'Guard,Charge' 'Burst,Reap'\n",
      " 'Regen,Mixed Damage' 'Regen,Burst' 'Support,Damage'\n",
      " 'Initiator,Magic Damage' 'Crowd Control,Damage' 'Regen,Damage'\n",
      " 'Damage,Crowd Control' 'Initiator,Guard' 'Regen,Control' 'Poke,Guard'\n",
      " 'Burst,Control' 'Chase,Magic Damage' 'Damage,Chase' 'Finisher/Damage'\n",
      " 'Chase/Burst' 'Damage/Regen' 'Support/Crowd Control'\n",
      " 'Damage/Crowd Control' 'Regen/Damage' 'Control/Regen' 'Charge/Burst']\n",
      "['Gold Laner' 'Jungler' 'Roamer' 'Exp Laner' 'Mid Laner' 'EXP Laner']\n",
      "[nan 'Exp Laner' 'Jungler' 'Gold Laner, Jungler' 'Roamer, Gold Laner'\n",
      " 'Gold Laner' 'Mid Laner' 'Roamer' 'Roamer, Exp Laner' 'none']\n"
     ]
    }
   ],
   "source": [
    "print(df['roles'].unique())\n",
    "print(df['specialities'].unique())\n",
    "print(df['lane'].unique())\n",
    "print(df['possible_lanes'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30319e48",
   "metadata": {},
   "source": [
    "## Function for Encoding State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1502ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_state(ally_picks, enemy_picks):\n",
    "    \n",
    "    ally_h,  ally_r,  ally_s,  ally_l  = encode_team(ally_picks)\n",
    "    enemy_h, enemy_r, enemy_s, enemy_l = encode_team(enemy_picks)\n",
    "\n",
    "    state = np.concatenate([\n",
    "        ally_h, enemy_h,   # heroes  (262)\n",
    "        ally_r, enemy_r,   # roles    (12)\n",
    "        ally_s, enemy_s,   # specs    (32)\n",
    "        ally_l, enemy_l,   # lanes    (10)\n",
    "    ])                     # total = 316 dimension of vectors\n",
    "\n",
    "    return torch.tensor(state, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cec922f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape: torch.Size([316])\n",
      "\n",
      "── Heroes ──\n",
      "Ally  : ['Akai', 'Karrie', 'Yu Zhong', 'Fredrinn']\n",
      "Enemy : ['Fanny', 'Lesley', 'Gusion']\n",
      "\n",
      "── Roles ──\n",
      "Ally  : ['Fighter', 'Marksman', 'Support', 'Tank']\n",
      "Enemy : ['Assassin', 'Marksman']\n",
      "\n",
      "── Specialities ──\n",
      "Ally  : ['Chase', 'Crowd Control', 'Damage', 'Guard', 'Reap', 'Regen']\n",
      "Enemy : ['Burst', 'Chase', 'Magic Damage', 'Reap']\n",
      "\n",
      "── Lanes ──\n",
      "Ally  : ['Exp Laner', 'Gold Laner', 'Jungler', 'Roamer']\n",
      "Enemy : ['Gold Laner', 'Jungler']\n"
     ]
    }
   ],
   "source": [
    "# Test encode_state with known heroes\n",
    "ally_picks  = ['Yu Zhong', 'Fredrinn', 'Karrie', 'Akai']       # 3 ally picks\n",
    "enemy_picks = ['Fanny', 'Gusion', 'Lesley']     # 3 enemy picks\n",
    "\n",
    "state = encode_state(ally_picks, enemy_picks)\n",
    "print(f\"State shape: {state.shape}\")  # Should be torch.Size([316])\n",
    "\n",
    "# ── Slice and decode each section ─────────────────────────────────────────────\n",
    "ally_h   = state[0:131]\n",
    "enemy_h  = state[131:262]\n",
    "ally_r   = state[262:268]\n",
    "enemy_r  = state[268:274]\n",
    "ally_s   = state[274:290]\n",
    "enemy_s  = state[290:306]\n",
    "ally_l   = state[306:311]\n",
    "enemy_l  = state[311:316]\n",
    "\n",
    "# Print decoded heroes\n",
    "print(\"\\n── Heroes ──\")\n",
    "print(\"Ally  :\", [id_to_hero[i] for i in torch.where(ally_h  == 1)[0].tolist()])\n",
    "print(\"Enemy :\", [id_to_hero[i] for i in torch.where(enemy_h == 1)[0].tolist()])\n",
    "\n",
    "# Print decoded roles\n",
    "print(\"\\n── Roles ──\")\n",
    "print(\"Ally  :\", [ROLES[i] for i in torch.where(ally_r == 1)[0].tolist()])\n",
    "print(\"Enemy :\", [ROLES[i] for i in torch.where(enemy_r == 1)[0].tolist()])\n",
    "\n",
    "# Print decoded specs\n",
    "print(\"\\n── Specialities ──\")\n",
    "print(\"Ally  :\", [SPECS[i] for i in torch.where(ally_s == 1)[0].tolist()])\n",
    "print(\"Enemy :\", [SPECS[i] for i in torch.where(enemy_s == 1)[0].tolist()])\n",
    "\n",
    "# Print decoded lanes\n",
    "print(\"\\n── Lanes ──\")\n",
    "print(\"Ally  :\", [LANES[i] for i in torch.where(ally_l == 1)[0].tolist()])\n",
    "print(\"Enemy :\", [LANES[i] for i in torch.where(enemy_l == 1)[0].tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b69cb5",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f907b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PICK_ORDER = [0, 1, 1, 0, 0, 1, 1, 0, 0, 1]\n",
    "\n",
    "class MLBBDraftEnv:\n",
    "    def __init__(self, win_heroes, lose_heroes, fp_is_win: bool, perspective: int = 0):\n",
    "        if fp_is_win:\n",
    "            self.team     = {0: win_heroes,  1: lose_heroes}\n",
    "            self.team_won = {0: True,         1: False}\n",
    "        else:\n",
    "            self.team     = {0: lose_heroes, 1: win_heroes}\n",
    "            self.team_won = {0: False,        1: True}\n",
    "        self.perspective = perspective\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_idx = 0\n",
    "        self.picks    = {0: [], 1: []}\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        ally  = self.picks[self.perspective]\n",
    "        enemy = self.picks[1 - self.perspective]\n",
    "        return encode_state(ally, enemy)\n",
    "\n",
    "    def step(self, hero):\n",
    "        assert self.step_idx < 10, \"Episode already finished.\"\n",
    "        state  = self._get_state()\n",
    "        picker = PICK_ORDER[self.step_idx]\n",
    "        action = hero_to_id[hero]\n",
    "\n",
    "        self.picks[picker].append(hero)\n",
    "        self.step_idx += 1\n",
    "\n",
    "        done       = (self.step_idx == 10)\n",
    "        next_state = self._get_state()\n",
    "\n",
    "        reward = 0.0\n",
    "        if done:\n",
    "            reward = 1.0 if self.team_won[self.perspective] else -1.0\n",
    "\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "    def run_episode(self):  \n",
    "        self.reset()\n",
    "        transitions = []\n",
    "        pick_counts = {0: 0, 1: 0}\n",
    "\n",
    "        for step in range(10):\n",
    "            picker = PICK_ORDER[step]\n",
    "            hero   = self.team[picker][pick_counts[picker]]\n",
    "            pick_counts[picker] += 1\n",
    "\n",
    "            s, a, r, ns, done = self.step(hero)\n",
    "\n",
    "            if picker == self.perspective:\n",
    "                transitions.append((s, a, r, ns, done))\n",
    "\n",
    "        return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61bcaf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches processed : 9122\n",
      "Skipped           : 0\n",
      "Total transitions : 91220\n"
     ]
    }
   ],
   "source": [
    "def build_transitions_from_dataset(df_match, both_perspectives=True):\n",
    "    all_transitions = []\n",
    "    skipped = 0\n",
    "\n",
    "    for _, row in df_match.iterrows():\n",
    "        win_heroes  = [row[f'winpick{i}'].strip() for i in range(1, 6)]\n",
    "        lose_heroes = [row[f'losepick{i}'].strip() for i in range(1, 6)]\n",
    "\n",
    "        if any(h not in hero_to_id for h in win_heroes + lose_heroes):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        fp_is_win    = random.random() < 0.5\n",
    "        perspectives = [0, 1] if both_perspectives else [random.randint(0, 1)]\n",
    "\n",
    "        for pov in perspectives:\n",
    "            env = MLBBDraftEnv(win_heroes, lose_heroes, fp_is_win, perspective=pov)\n",
    "            all_transitions.extend(env.run_episode())\n",
    "\n",
    "    print(f\"Matches processed : {len(df_match) - skipped}\")\n",
    "    print(f\"Skipped           : {skipped}\")\n",
    "    print(f\"Total transitions : {len(all_transitions)}\")\n",
    "    return all_transitions\n",
    "\n",
    "transitions = build_transitions_from_dataset(df_match_history, both_perspectives=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0ae53",
   "metadata": {},
   "source": [
    "## Making of Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f39f660",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d4ebb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset:\n",
      "  X shape : (18244, 316)\n",
      "  y shape : (18244,)\n"
     ]
    }
   ],
   "source": [
    "# from collections import deque\n",
    "import random\n",
    "\n",
    "# Load the preprocessed 316-dim dataset we saved earlier\n",
    "data  = np.load('data/draft_dataset_316.npz')\n",
    "X_all = data['X']  # (15808, 316) — input vectors\n",
    "y_all = data['y']  # (15808,)     — labels: 1=ally wins, 0=ally loses\n",
    "\n",
    "print(f\"Loaded dataset:\")\n",
    "print(f\"  X shape : {X_all.shape}\")\n",
    "print(f\"  y shape : {y_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438931cc",
   "metadata": {},
   "source": [
    "### Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset samples    : 18244\n",
      "Total experiences  : 91220\n",
      "State dim: 316 | Device: cpu\n",
      "Replay buffer capacity : 91220\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES       = len(X_all)\n",
    "HEROES_PER_SAMPLE = 5\n",
    "TOTAL_EXPERIENCES = NUM_SAMPLES * HEROES_PER_SAMPLE\n",
    "\n",
    "print(f\"Dataset samples    : {NUM_SAMPLES}\")\n",
    "print(f\"Total experiences  : {TOTAL_EXPERIENCES}\")\n",
    "\n",
    "STATE_DIM  = NUM_HEROES * 2 + NUM_ROLES * 2 + NUM_SPECS * 2 + NUM_LANES * 2  # 316\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"State dim: {STATE_DIM} | Device: {device}\")\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory   = []\n",
    "        self.position = 0\n",
    "\n",
    "    def insert(self, state, action, reward, next_state, done):\n",
    "        transition = (\n",
    "            state.unsqueeze(0),\n",
    "            torch.tensor([[action]],  dtype=torch.long),\n",
    "            torch.tensor([[reward]],  dtype=torch.float32),\n",
    "            next_state.unsqueeze(0),\n",
    "            torch.tensor([[done]],    dtype=torch.bool),\n",
    "        )\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = transition\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        assert self.can_sample(batch_size)\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        return (torch.cat(states), torch.cat(actions), torch.cat(rewards),\n",
    "                torch.cat(next_states), torch.cat(dones))\n",
    "\n",
    "    def can_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size * 10\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "# Initialize with auto maxlen\n",
    "memory = ReplayMemory(capacity=TOTAL_EXPERIENCES)\n",
    "print(f\"Replay buffer capacity : {TOTAL_EXPERIENCES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5ac1a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cpu\n"
     ]
    }
   ],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim=316, output_dim=131):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),  # 316 → 256\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),        # 512 → 256\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),        # 256 → 128\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, output_dim)  # 128 → 131 Q-values\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # returns Q-value for all 131 heroes\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model     = DQN(input_dim=316, output_dim=131).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f\"Using device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "65c567b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay buffer filled: 91220 transitions\n",
      "Steps per epoch: 356\n",
      "\n",
      "Epoch   0/100 | Train Loss: 0.1058  Acc: 27.7% | Val Loss: 0.1009  Acc: 7.4%\n",
      "Best model saved (val_loss=0.1009)\n",
      "Epoch  10/100 | Train Loss: 0.0972  Acc: 7.7% | Val Loss: 0.0971  Acc: 8.6%\n",
      "Best model saved (val_loss=0.0971)\n",
      "Epoch  20/100 | Train Loss: 0.0682  Acc: 9.5% | Val Loss: 0.0650  Acc: 10.9%\n",
      "Best model saved (val_loss=0.0650)\n",
      "Epoch  30/100 | Train Loss: 0.0442  Acc: 9.4% | Val Loss: 0.0374  Acc: 7.8%\n",
      "Best model saved (val_loss=0.0374)\n",
      "Epoch  40/100 | Train Loss: 0.0298  Acc: 9.6% | Val Loss: 0.0268  Acc: 6.6%\n",
      "Best model saved (val_loss=0.0268)\n",
      "Epoch  50/100 | Train Loss: 0.0237  Acc: 9.7% | Val Loss: 0.0208  Acc: 7.0%\n",
      "Best model saved (val_loss=0.0208)\n",
      "Epoch  60/100 | Train Loss: 0.0194  Acc: 9.7% | Val Loss: 0.0202  Acc: 9.8%\n",
      "Best model saved (val_loss=0.0202)\n",
      "Epoch  70/100 | Train Loss: 0.0174  Acc: 9.9% | Val Loss: 0.0214  Acc: 12.5%\n",
      "Epoch  80/100 | Train Loss: 0.0161  Acc: 9.9% | Val Loss: 0.0281  Acc: 9.8%\n",
      "Epoch  90/100 | Train Loss: 0.0176  Acc: 9.9% | Val Loss: 0.0327  Acc: 8.6%\n",
      "\n",
      "Final  : data/draft_model_bellman.pth\n",
      "Best   : data/draft_model_bellman_best.pth (val_loss=0.0202)\n"
     ]
    }
   ],
   "source": [
    "GAMMA             = 0.99\n",
    "BATCH_SIZE        = 256\n",
    "NUM_EPOCHS        = 100\n",
    "TARGET_SYNC_EVERY = 10\n",
    "LR                = 0.0001\n",
    "\n",
    "def train(transitions, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE):\n",
    "    memory = ReplayMemory(capacity=len(transitions))\n",
    "    for s, a, r, ns, done in transitions:\n",
    "        memory.insert(s, a, r, ns, done)\n",
    "    print(f\"Replay buffer filled: {len(memory)} transitions\")\n",
    "\n",
    "    if not memory.can_sample(batch_size):\n",
    "        print(f\"ERROR: Need at least {batch_size * 10} transitions, got {len(memory)}\")\n",
    "        return None, None\n",
    "\n",
    "    policy_net = DQN(STATE_DIM, NUM_HEROES).to(device)\n",
    "    target_net = DQN(STATE_DIM, NUM_HEROES).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer       = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "    criterion       = nn.MSELoss()\n",
    "    steps_per_epoch = max(len(memory) // batch_size, 1)\n",
    "    best_loss       = float('inf')\n",
    "    print(f\"Steps per epoch: {steps_per_epoch}\\n\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        policy_net.train()\n",
    "        epoch_loss, epoch_correct = 0.0, 0\n",
    "\n",
    "        for _ in range(steps_per_epoch):\n",
    "            states, actions, rewards, next_states, dones = memory.sample(batch_size)\n",
    "            states, actions, rewards, next_states, dones = (\n",
    "                states.to(device), actions.to(device), rewards.to(device),\n",
    "                next_states.to(device), dones.to(device)\n",
    "            )\n",
    "\n",
    "            q_action = policy_net(states).gather(1, actions)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                max_next_q = target_net(next_states).max(dim=1, keepdim=True).values\n",
    "                target_q   = rewards + GAMMA * max_next_q * (~dones).float()\n",
    "\n",
    "            loss = criterion(q_action, target_q)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss    += loss.item()\n",
    "            epoch_correct += ((q_action.detach() > 0) == (rewards > 0)).sum().item()\n",
    "\n",
    "        avg_loss = epoch_loss    / steps_per_epoch\n",
    "        accuracy = epoch_correct / (steps_per_epoch * batch_size) * 100\n",
    "\n",
    "        if epoch % TARGET_SYNC_EVERY == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            policy_net.eval()\n",
    "            with torch.no_grad():\n",
    "                vs, va, vr, vns, vd = memory.sample(batch_size)\n",
    "                vs, va, vr, vns, vd = (vs.to(device), va.to(device), vr.to(device),\n",
    "                                        vns.to(device), vd.to(device))\n",
    "                vq       = policy_net(vs).gather(1, va)\n",
    "                vt       = vr + GAMMA * target_net(vns).max(dim=1, keepdim=True).values * (~vd).float()\n",
    "                val_loss = criterion(vq, vt).item()\n",
    "                val_acc  = ((vq.detach() > 0) == (vr > 0)).float().mean().item() * 100\n",
    "\n",
    "            print(f\"Epoch {epoch:3d}/{num_epochs} | \"\n",
    "                  f\"Train Loss: {avg_loss:.4f}  Acc: {accuracy:.1f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f}  Acc: {val_acc:.1f}%\")\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(policy_net.state_dict(), 'data/draft_model_bellman_best.pth')\n",
    "                print(f\"Best model saved (val_loss={best_loss:.4f})\")\n",
    "\n",
    "            policy_net.train()\n",
    "\n",
    "    torch.save(policy_net.state_dict(), 'data/draft_model_bellman.pth')\n",
    "    print(f\"\\nFinal  : data/draft_model_bellman.pth\")\n",
    "    print(f\"Best   : data/draft_model_bellman_best.pth (val_loss={best_loss:.4f})\")\n",
    "    return policy_net, target_net\n",
    "\n",
    "# ── Run ───────────────────────────────────────────────────────────────────────\n",
    "policy_net, target_net = train(transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2fd9c",
   "metadata": {},
   "source": [
    "## Recommendation Function using Trained DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102cdb45",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "268f8326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# ── 1. LOAD THE TRAINED MODEL ──────────────────────────────────────────────────\n",
    "model = DQN(input_dim=316, output_dim=131).to(device)\n",
    "model.load_state_dict(torch.load('data/draft_model_bellman_best.pth'))\n",
    "model.eval()  # ← switch to evaluation mode (disables dropout)\n",
    "print(\"Model loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a635391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model, ally_picks, enemy_picks, banned, player_lanes=None, top_n=10):\n",
    "    ally_heroes  = [p['hero'] for p in ally_picks]\n",
    "    enemy_heroes = [p['hero'] for p in enemy_picks]\n",
    "\n",
    "    state = encode_state(ally_heroes, enemy_heroes).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        q_values = model(state.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "    unavailable = set(ally_heroes + enemy_heroes + banned)\n",
    "\n",
    "    all_scored = [\n",
    "        (hero, q_values[idx].item())\n",
    "        for hero, idx in hero_to_id.items()\n",
    "        if hero not in unavailable\n",
    "    ]\n",
    "\n",
    "    if player_lanes is None:\n",
    "        all_scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        return {'All': [{'hero': h, 'score': round(s, 4),\n",
    "                         'roles': hero_roles.get(h, []),\n",
    "                         'lane':  hero_lanes.get(h, [])} for h, s in all_scored[:top_n]]}\n",
    "\n",
    "    results = {}\n",
    "    for lane in player_lanes:\n",
    "        lane_scored = [(h, s) for h, s in all_scored if lane in hero_lanes.get(h, [])]\n",
    "        lane_scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        results[lane] = [{'hero': h, 'score': round(s, 4),\n",
    "                          'roles': hero_roles.get(h, []),\n",
    "                          'specs': list(hero_specs.get(h, [])),\n",
    "                          'lane':  hero_lanes.get(h, [])} for h, s in lane_scored[:top_n]]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3abca05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def recommend(model, ally_picks, enemy_picks, banned, player_lanes=None, top_n=10):\n",
    "#     ally_heroes  = [p['hero'] for p in ally_picks]\n",
    "#     enemy_heroes = [p['hero'] for p in enemy_picks]\n",
    "\n",
    "#     state = encode_state(ally_heroes, enemy_heroes).to(device)\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         q_values = model(state.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "#     unavailable    = set(ally_heroes + enemy_heroes + banned)\n",
    "#     ally_role_set  = set(r for h in ally_heroes for r in hero_roles.get(h, []))\n",
    "#     ally_lane_set  = set(p['lane'] for p in ally_picks if p.get('lane'))\n",
    "\n",
    "#     # ── Dynamic spec context ───────────────────────────────────────────────\n",
    "#     ally_spec_set  = set(s for h in ally_heroes  for s in hero_specs.get(h, []))\n",
    "#     enemy_spec_set = set(s for h in enemy_heroes for s in hero_specs.get(h, []))\n",
    "\n",
    "#     # Specs your ally team is stacking too much of\n",
    "#     spec_counts   = Counter(s for h in ally_heroes for s in hero_specs.get(h, []))\n",
    "#     stacked_specs = {s for s, count in spec_counts.items() if count >= 2}\n",
    "\n",
    "#     # ── Dynamic desired specs — react to enemy composition ─────────────────\n",
    "#     desired_specs = set()\n",
    "#     if enemy_heroes:  # only react if enemy has picks\n",
    "#         if 'Burst'        in enemy_spec_set: desired_specs |= {'Guard', 'Regen'}\n",
    "#         if 'Chase'        in enemy_spec_set: desired_specs |= {'Crowd Control', 'Control'}\n",
    "#         if 'Reap'         in enemy_spec_set: desired_specs |= {'Guard', 'Initiator'}\n",
    "#         if 'Damage'       in enemy_spec_set: desired_specs |= {'Regen'}\n",
    "#         if 'Magic Damage' in enemy_spec_set: desired_specs |= {'Regen', 'Guard'}\n",
    "#         if 'Charge'       in enemy_spec_set: desired_specs |= {'Crowd Control', 'Control'}\n",
    "#         if 'Poke'         in enemy_spec_set: desired_specs |= {'Initiator', 'Chase'}\n",
    "\n",
    "#     # Only bonus specs that are actually missing from ally team\n",
    "#     missing_specs = desired_specs - ally_spec_set\n",
    "\n",
    "#     all_scored = []\n",
    "#     for hero, idx in hero_to_id.items():\n",
    "#         if hero in unavailable:\n",
    "#             continue\n",
    "\n",
    "#         score     = q_values[idx].item()\n",
    "#         hero_spec = set(hero_specs.get(hero, []))\n",
    "\n",
    "#         # Penalty — duplicate role\n",
    "#         for r in hero_roles.get(hero, []):\n",
    "#             if r in ally_role_set:\n",
    "#                 score -= 0.3\n",
    "\n",
    "#         # Penalty — lane already taken\n",
    "#         for l in hero_lanes.get(hero, []):\n",
    "#             if l in ally_lane_set:\n",
    "#                 score -= 0.3\n",
    "\n",
    "#         # Bonus — fills a gap against enemy composition\n",
    "#         score += 0.15 * len(hero_spec & missing_specs)\n",
    "\n",
    "#         # Penalty — stacks what ally already has too much of\n",
    "#         score -= 0.10 * len(hero_spec & stacked_specs)\n",
    "\n",
    "#         all_scored.append((hero, score))\n",
    "\n",
    "#     if player_lanes is None:\n",
    "#         all_scored.sort(key=lambda x: x[1], reverse=True)\n",
    "#         return {'All': [{'hero': h, 'score': round(s, 4),\n",
    "#                          'roles': hero_roles.get(h, []),\n",
    "#                          'lane':  hero_lanes.get(h, [])} for h, s in all_scored[:top_n]]}\n",
    "\n",
    "#     results = {}\n",
    "#     for lane in player_lanes:\n",
    "#         lane_scored = [(h, s) for h, s in all_scored if lane in hero_lanes.get(h, [])]\n",
    "#         lane_scored.sort(key=lambda x: x[1], reverse=True)\n",
    "#         results[lane] = [{'hero': h, 'score': round(s, 4),\n",
    "#                           'roles': hero_roles.get(h, []),\n",
    "#                           'specs': list(hero_specs.get(h, [])),\n",
    "#                           'lane':  hero_lanes.get(h, [])} for h, s in lane_scored[:top_n]]\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c03e9",
   "metadata": {},
   "source": [
    "### Example Usage of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1: Load or Train Model\n",
      "============================================================\n",
      "✅ Saved model found — skipping training.\n",
      "Model ready for recommendations.\n",
      "\n",
      "============================================================\n",
      "Step 2: Sample Recommendations\n",
      "============================================================\n",
      "Example 1: Exp Laner + Gold Laner\n",
      "Banned heroes: ['Kalea', 'Balmond', 'Bane', 'Miya', 'Chou', 'Joy', 'Paquito', 'Saber', 'Novaria', 'Minotaur']\n",
      "\n",
      "  Exp Laner recommendations:\n",
      "     1. Badang               1.0445  ['Fighter']\n",
      "     2. Masha                0.9884  ['Fighter', 'Tank']\n",
      "     3. Lukas                0.9589  ['Fighter']\n",
      "     4. Uranus               0.9466  ['Tank']\n",
      "     5. Cici                 0.9433  ['Fighter']\n",
      "     6. Sun                  0.9419  ['Fighter']\n",
      "     7. X.Borg               0.9413  ['Fighter']\n",
      "     8. Guinevere            0.9208  ['Fighter']\n",
      "     9. Yu Zhong             0.9056  ['Fighter']\n",
      "    10. Arlott               0.9039  ['Fighter', 'Assassin']\n",
      "    11. Thamuz               0.8983  ['Fighter']\n",
      "    12. Gloo                 0.8894  ['Tank']\n",
      "    13. Terizla              0.8863  ['Fighter']\n",
      "    14. Alice                0.8745  ['Mage', 'Tank']\n",
      "    15. Ruby                 0.8742  ['Fighter', 'Tank']\n",
      "    16. Freya                0.8690  ['Fighter']\n",
      "    17. Benedetta            0.8668  ['Assassin']\n",
      "    18. Zilong               0.8619  ['Assassin', 'Fighter']\n",
      "    19. Martis               0.8585  ['Fighter']\n",
      "    20. Edith                0.8580  ['Tank', 'Marksman']\n",
      "\n",
      "  Gold Laner recommendations:\n",
      "     1. Wanwan               0.9481  ['Marksman']\n",
      "     2. Granger              0.8799  ['Marksman']\n",
      "     3. Natan                0.8797  ['Marksman']\n",
      "     4. Irithel              0.8793  ['Marksman']\n",
      "     5. Lesley               0.8751  ['Marksman', 'Assassin']\n",
      "     6. Hanabi               0.8558  ['Marksman']\n",
      "     7. Kimmy                0.8537  ['Marksman', 'Mage']\n",
      "     8. Ixia                 0.8518  ['Marksman']\n",
      "     9. Obsidia              0.8457  ['Marksman']\n",
      "    10. Popol and Kupa       0.8331  ['Marksman']\n",
      "    11. Melissa              0.8244  ['Marksman']\n",
      "    12. Clint                0.8199  ['Marksman']\n",
      "    13. Moskov               0.8170  ['Marksman']\n",
      "    14. Beatrix              0.8165  ['Marksman']\n",
      "    15. Claude               0.8112  ['Marksman']\n",
      "    16. Layla                0.8095  ['Marksman']\n",
      "    17. Brody                0.8042  ['Marksman']\n",
      "    18. Bruno                0.8026  ['Marksman']\n",
      "    19. Harith               0.7894  ['Mage']\n",
      "\n",
      "Example 2: Jungler + Exp Laner\n",
      "\n",
      "  Jungler recommendations (top 10):\n",
      "     1. Baxia                0.9260  ['Tank']\n",
      "     2. Suyou                0.9064  ['Assassin', 'Fighter']\n",
      "     3. Helcurt              0.8477  ['Assassin']\n",
      "     4. Joy                  0.8401  ['Assassin']\n",
      "     5. Roger                0.8341  ['Fighter', 'Marksman']\n",
      "     6. Yin                  0.8304  ['Fighter']\n",
      "     7. Nolan                0.8162  ['Assassin']\n",
      "     8. Barats               0.7998  ['Tank', 'Fighter']\n",
      "     9. Harley               0.7996  ['Mage', 'Assassin']\n",
      "    10. Fredrinn             0.7956  ['Tank', 'Fighter']\n",
      "\n",
      "  Exp Laner recommendations (top 10):\n",
      "     1. Masha                0.8887  ['Fighter', 'Tank']\n",
      "     2. Lukas                0.8731  ['Fighter']\n",
      "     3. Uranus               0.8628  ['Tank']\n",
      "     4. Silvanna             0.8576  ['Fighter']\n",
      "     5. Badang               0.8535  ['Fighter']\n",
      "     6. Guinevere            0.8472  ['Fighter']\n",
      "     7. X.Borg               0.8424  ['Fighter']\n",
      "     8. Sun                  0.8359  ['Fighter']\n",
      "     9. Zilong               0.8317  ['Assassin', 'Fighter']\n",
      "    10. Terizla              0.8288  ['Fighter']\n",
      "\n",
      "Example 3: Gold Laner, no picks yet\n",
      "\n",
      "  Gold Laner recommendations:\n",
      "     1. Kimmy                0.5730  ['Gold Laner']\n",
      "     2. Popol and Kupa       0.5667  ['Gold Laner']\n",
      "     3. Wanwan               0.5611  ['Gold Laner']\n",
      "     4. Granger              0.5560  ['Gold Laner']\n",
      "     5. Bruno                0.5469  ['Gold Laner']\n",
      "     6. Ixia                 0.5421  ['Gold Laner']\n",
      "     7. Irithel              0.5397  ['Gold Laner']\n",
      "     8. Harith               0.5366  ['Gold Laner']\n",
      "     9. Lesley               0.5348  ['Gold Laner']\n",
      "    10. Natan                0.5344  ['Gold Laner']\n",
      "    11. Obsidia              0.5337  ['Gold Laner']\n",
      "    12. Brody                0.5332  ['Gold Laner']\n",
      "    13. Melissa              0.5286  ['Gold Laner']\n",
      "    14. Claude               0.5281  ['Gold Laner']\n",
      "    15. Beatrix              0.5201  ['Gold Laner']\n",
      "    16. Clint                0.5163  ['Gold Laner']\n",
      "    17. Hanabi               0.5158  ['Gold Laner']\n",
      "    18. Layla                0.5128  ['Gold Laner']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 1: Load or Train Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if os.path.exists('data/draft_model_bellman_best.pth'):\n",
    "    print(\"✅ Saved model found — skipping training.\")\n",
    "    policy_net = DQN(STATE_DIM, NUM_HEROES).to(device)\n",
    "    policy_net.load_state_dict(torch.load('data/draft_model_bellman_best.pth', map_location=device))\n",
    "    policy_net.eval()\n",
    "else:\n",
    "    print(\"No saved model found — training from scratch...\")\n",
    "    transitions = build_transitions_from_dataset(df_match_history, both_perspectives=True)\n",
    "    policy_net, target_net = train(transitions)\n",
    "    policy_net.load_state_dict(torch.load('data/draft_model_bellman_best.pth', map_location=device))\n",
    "    policy_net.eval()\n",
    "    print(\"Training complete, best model loaded.\")\n",
    "\n",
    "print(\"Model ready for recommendations.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 2: Sample Recommendations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Example 1: Exp Laner + Gold Laner\")\n",
    "exampleOneBanned = getBannedHeroes()\n",
    "results = recommend(\n",
    "    model        = policy_net,\n",
    "    ally_picks   = [{'hero': 'Lancelot', 'lane': 'Jungler'},\n",
    "                    {'hero': 'Khufra',  'lane': 'Roamer'},\n",
    "                    {'hero': 'Zetian',  'lane': 'Mid Laner'}],\n",
    "\n",
    "    enemy_picks  = [{'hero': 'Fredrinn',     'lane': 'Jungler'},\n",
    "                    {'hero': 'Silvanna',     'lane': 'Exp Laner'},\n",
    "                    {'hero': 'Karrie',    'lane': 'Gold Laner'},\n",
    "                    {'hero': 'Grock', 'lane': 'Roamer'}],\n",
    "    banned       = exampleOneBanned,\n",
    "    player_lanes = ['Exp Laner', 'Gold Laner'],\n",
    "    top_n        = 20\n",
    ")\n",
    "print(f\"Banned heroes: {exampleOneBanned}\")\n",
    "for lane, heroes in results.items():\n",
    "    print(f\"\\n  {lane} recommendations:\")\n",
    "    for rank, r in enumerate(heroes, 1):\n",
    "        print(f\"    {rank:2}. {r['hero']:<20} {r['score']:.4f}  {r['roles']}\")\n",
    "\n",
    "print(\"\\nExample 2: Jungler + Exp Laner\")\n",
    "results = recommend(\n",
    "    model        = policy_net,\n",
    "    ally_picks   = [{'hero': 'Gusion', 'lane': 'Mid Laner'},\n",
    "                    {'hero': 'Atlas',  'lane': 'Roamer'}],\n",
    "\n",
    "    enemy_picks  = [{'hero': 'Fanny',  'lane': 'Jungler'},\n",
    "                    {'hero': 'Karrie', 'lane': 'Gold Laner'},\n",
    "                    {'hero': 'Esmeralda', 'lane': 'Exp Laner'}],\n",
    "    banned       = getBannedHeroes(),\n",
    "    player_lanes = ['Jungler', 'Exp Laner'],\n",
    "    top_n        = 10\n",
    ")\n",
    "for lane, heroes in results.items():\n",
    "    print(f\"\\n  {lane} recommendations (top {len(heroes)}):\")\n",
    "    for rank, r in enumerate(heroes, 1):\n",
    "        print(f\"    {rank:2}. {r['hero']:<20} {r['score']:.4f}  {r['roles']}\")\n",
    "\n",
    "print(\"\\nExample 3: Gold Laner, no picks yet\")\n",
    "results = recommend(\n",
    "    model        = policy_net,\n",
    "    ally_picks   = [],\n",
    "    enemy_picks  = [],\n",
    "    banned       = getBannedHeroes(),\n",
    "    player_lanes = ['Gold Laner'],\n",
    "    top_n        = 20\n",
    ")\n",
    "for lane, heroes in results.items():\n",
    "    print(f\"\\n  {lane} recommendations:\")\n",
    "    for rank, r in enumerate(heroes, 1):\n",
    "        print(f\"    {rank:2}. {r['hero']:<20} {r['score']:.4f}  {r['lane']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
